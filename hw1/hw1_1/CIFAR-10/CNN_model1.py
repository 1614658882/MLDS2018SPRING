# #!/bin/bash
# 

import sys
import numpy as np
import pandas
from keras.models import Sequential
from keras.layers import Dense, AlphaDropout, Dropout, Activation, Flatten
from keras.optimizers import Adam, rmsprop
from keras.utils import to_categorical
from keras.layers import Conv2D, MaxPooling2D, LeakyReLU
from keras import backend as K
from keras.layers.normalization import BatchNormalization
from keras.preprocessing.image import ImageDataGenerator
from keras.datasets import cifar10

if __name__ == "__main__":
    # Fix random seed for reproducibility.
    seed = 777
    np.random.seed(seed)
    print ('Fixed random seed for reproducibility.')

    
    batch_size = 32
    num_classes = 10
    epochs = 100
    # Input image dimensions.
    rowsImage, colsImage = 32, 32

    # the data, split between train and test sets
    (x_data_train, y_data_train), (x_data_test, y_data_test) = cifar10.load_data()
    # print('x_train shape:', x_data_train.shape)
    
    # Reshape (rowsImage * colsImage) to (rowsImage, colsImage) array.
    if K.image_data_format() == 'channels_first':
        x_data_train = x_data_train.reshape((x_data_train.shape[0], 3, rowsImage, colsImage))
        x_data_test = x_data_test.reshape(x_data_test.shape[0], 3, rowsImage, colsImage)
        input_shape = (3, rowsImage, colsImage)
    else:
        x_data_train = x_data_train.reshape((x_data_train.shape[0], rowsImage, colsImage, 3))
        x_data_test = x_data_test.reshape(x_data_test.shape[0], rowsImage, colsImage, 3)
        input_shape = (rowsImage, colsImage, 3)
    
    # Scale to 0 ~ 1 on training set.
    x_data_train = x_data_train.astype('float32') / 255.0
    x_data_test = x_data_test.astype('float32') / 255.0
    print ('Scaled to 0 ~ 1 on training set.')

    # Convert labels to one hot encoding.
    # y_data_train = to_categorical(y_data_train)
    y_data_train = to_categorical(y_data_train)
    y_data_test = to_categorical(y_data_test)

    # Create the model.
    model = Sequential()
    # Conv block 1: 64 output filters.
    # model.add(Conv2D(32, kernel_size=(3, 3),
    #              padding='same',
    #              activation='selu',
    #              kernel_initializer='lecun_normal',
    #              bias_initializer='zeros',
    #              input_shape=input_shape))
    model.add(Conv2D(49, (3, 3), padding='same',
                    input_shape=x_data_train.shape[1:],kernel_initializer='lecun_normal',bias_initializer='zeros'))
    model.add(Activation('selu'))
    model.add(Conv2D(49, (3, 3),kernel_initializer='lecun_normal',bias_initializer='zeros'))
    model.add(Activation('selu'))
    model.add(MaxPooling2D(pool_size=(4, 4)))
    model.add(AlphaDropout(0.1))

    # Fully-connected classifier.
    model.add(Flatten())
    model.add(Dense(512,kernel_initializer='lecun_normal',bias_initializer='zeros'))
    model.add(Activation('selu'))
    model.add(AlphaDropout(0.2))
    model.add(Dense(num_classes,kernel_initializer='lecun_normal',bias_initializer='zeros'))
    model.add(Activation('softmax'))
    print ('Created the model.')
    print (model.summary())
    # # of parameters: 1,257,984

    # initiate RMSprop optimizer
    opt = rmsprop(lr=0.0001, decay=1e-6)
    # Compile the model.
    model.compile(loss = 'categorical_crossentropy', optimizer = opt, metrics = ['accuracy'])
    print ('Compiled the model.')
    # exit()

    datagen = ImageDataGenerator(
        featurewise_center=False,  # set input mean to 0 over the dataset
        samplewise_center=False,  # set each sample mean to 0
        featurewise_std_normalization=False,  # divide inputs by std of the dataset
        samplewise_std_normalization=False,  # divide each input by its std
        zca_whitening=False,  # apply ZCA whitening
        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)
        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)
        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)
        horizontal_flip=True,  # randomly flip images
        vertical_flip=False)  # randomly flip images

    # Compute quantities required for feature-wise normalization
    # (std, mean, and principal components if ZCA whitening is applied).
    datagen.fit(x_data_train)

    # Fit the model on the batches generated by datagen.flow().
    fitHistory = model.fit_generator(datagen.flow(x_data_train, y_data_train,
                                     batch_size=batch_size),
                        steps_per_epoch=x_data_train.shape[0] // batch_size,
                        epochs=epochs,
                        validation_data=(x_data_test, y_data_test))


    # # # Fit the model.
    # fitHistory = model.fit(x_data_train, y_data_train,
    #     batch_size = batch_size, epochs = epochs, verbose = 1,
    #     shuffle = True,
    #     validation_data=(x_data_test, y_data_test))

    # Save model to h5 file.
    model.save('CNN_model1.h5')

    # Save history of acc to npy file.
    np.save('train_acc_history_CNN_model1.npy', fitHistory.history['acc'])
    np.save('train_loss_history_CNN_model1.npy', fitHistory.history['loss'])
    np.save('test_acc_history_CNN_model1.npy', fitHistory.history['val_acc'])
    np.save('test_loss_history_CNN_model1.npy', fitHistory.history['val_loss'])

    # Report index of highest accuracy in training set and validation set.
    print ('tra_acc: ', np.amax(fitHistory.history['acc']), 'at epochs = ', np.argmax(fitHistory.history['acc']))
    print ('val_acc: ', np.amax(fitHistory.history['val_acc']), 'at epochs = ', np.argmax(fitHistory.history['val_acc']))
    # # # Remove plt before summit to github.
    # import matplotlib.pyplot as plt
    # # # Force matplotlib to not use any Xwindows backend.
    # # plt.switch_backend('agg')
    # # Summarize history for accuracy
    # plt.plot(fitHistory.history['acc'])
    # # plt.plot(fitHistory.history['val_acc'])
    # plt.title('Accuracy v.s. Epoch')
    # plt.ylabel('Accuracy')
    # plt.xlabel('# of epoch')
    # # plt.legend(['train', 'valid'], loc='lower right')
    # plt.savefig('Accuracy v.s. Epoch.png')